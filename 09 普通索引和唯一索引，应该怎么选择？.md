我们来深入探讨一下普通索引和唯一索引在性能上的差异，以及在业务开发中应该如何选择。

问题的核心是：**在业务代码已经能保证字段值唯一的前提下，从性能角度出发，是选择唯一索引，还是普通索引？**

为了回答这个问题，我们需要分别从“查询”和“更新”两个场景来分析它们的性能差异。

### 1. 查询性能的对比

我们先来看查询过程。假设执行的 SQL 语句是 `select id from T where k=5;`

* **唯一索引的查找过程：**
    索引树从上到下查找，当定位到叶子节点上 `k=5` 这条记录时，由于索引具有唯一性，数据库知道不可能存在第二条 `k=5` 的记录，所以它会立即停止查找，并返回结果。

* **普通索引的查找过程：**
    同样地，索引树查找到第一个满足 `k=5` 的记录后，它并不知道这是否是唯一的一条。为了找出所有满足条件的记录，它必须继续向后查找，直到碰到第一个不满足 `k=5` 条件的记录为止。

**这两者性能差距大吗？**

答案是：**微乎其微**。

`InnoDB` 从磁盘读取数据的最小单位是**数据页（Page）**，默认大小为 16KB。当数据库通过索引找到 `k=5` 这条记录时，它实际上已经把整个数据页加载到了内存（Buffer Pool）中。

对于普通索引，多出来的那一步“向后查找”的操作，是在**已经加载到内存的数据页**上进行的。这本质上只是一次内存中的指针移动和一次值的比较，对于现代 CPU 来说，这个耗时可以忽略不计。

所以，**单从查询性能上讲，普通索引和唯一索引的差别极小。**

### 2. 更新性能的对比 (核心差异)

更新操作的性能差异是这两类索引选择的关键，而这个差异的核心来自于一个叫 **`Change Buffer`** 的机制。

#### 什么是 Change Buffer？

简单来说，`Change Buffer` 是 `InnoDB` 的一块特殊缓存区。当我们要更新一个**二级索引**的数据时，如果这个索引所在的**数据页（Page）不在内存（Buffer Pool）中**，`InnoDB` 并不会立刻从磁盘把这个数据页读到内存里来修改（因为这涉及到一次昂贵的随机I/O），而是会先把“要对某某页面做一个什么修改”这个**操作指令**，先记录在 `Change Buffer`里。

这样，一次写操作就完成了，非常快。

#### Change Buffer 何时生效？

这些缓存在 `Change Buffer` 里的操作指令，会在未来某个时刻被应用（`merge`）到原始的数据页上。触发 `merge` 的时机通常有三个：
1.  下一次有查询请求访问这个数据页时。
2.  后台有专门的线程定期进行 `merge`。
3.  数据库正常关闭时。

#### 为什么唯一索引不能使用 Change Buffer？

因为唯一索引有一个“天职”：**保证记录的唯一性**。

当你要插入一条新记录时（比如 `k=4`），`InnoDB` 必须检查这个值 `4` 是否已经存在。为了完成这个检查，它**别无选择，必须将可能包含 `k=4` 的那个数据页从磁盘加载到内存中**，然后才能判断是否存在冲突。

既然数据页都已经被加载到内存了，那就直接在内存里更新好了，完全没有必要再使用 `Change Buffer`。

而普通索引没有唯一性约束，不需要做这个检查，所以它可以放心地使用 `Change aBuffer` 来优化写性能。

#### 两种情况下的更新流程对比

假设我们要插入一条新记录 `(4, 400)`：

* **情况一：目标数据页已在内存中**
    * **唯一索引**：找到3和5之间的位置，判断无冲突，插入，结束。
    * **普通索引**：找到3和5之间的位置，直接插入，结束。
    * **结论**：性能差异极小。

* **情况二：目标数据页不在内存中**
    * **唯一索引**：必须从磁盘**读取**数据页到内存，判断无冲突，插入，结束。这个过程多了一次昂贵的**随机读磁盘I/O**。
    * **普通索引**：直接将更新指令写入内存中的 `Change Buffer`，结束。
    * **结论**：普通索引的性能优势非常明显。

### 适用场景与实践建议

* `Change Buffer` 的核心收益在于，将多次针对同一个数据页的更新操作，在未来一次性地 `merge` 掉。如果一个数据页被写入后，在很长一段时间内都不会被读取，那么 `Change Buffer` 的收益就最大。
* 典型的**“写多读少”**业务，如账单系统、日志系统，就非常适合使用普通索引 + `Change Buffer` 的组合。
* 反之，如果一个业务的模式是“写入后立刻查询”，那 `Change Buffer` 反而会带来额外开销，因为刚写完缓存，下个读请求就立刻触发了 `merge` 操作。

**综合来看，除非你的业务有强制的唯一性约束需求，否则从性能角度出发，更推荐使用普通索引。**

### Change Buffer 与 Redo Log 的关系

这是一个常见的混淆点，我们来澄清一下：

* **Redo Log (重做日志)**：它的核心目标是保证数据库的**崩溃安全（Durability）**。它把对数据页的**随机写**操作，变成了对日志文件的**顺序写**，主要节省的是**随机写磁盘**的I/O消耗。
* **Change Buffer**：它的核心目标是**性能优化**。它针对的是不在内存中的二级索引页的更新，通过缓存操作指令，主要节省的是**随机读磁盘**的I/O消耗。

可以记为：**Redo Log 节省随机写，Change Buffer 节省随机读。**

---
### 结尾问题解析

> change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？

**答案是：不会丢失，数据是安全的。**

**原因如下：**

`Change Buffer` 本身虽然是一块内存，但对它的**操作过程，是需要被保护的**。这个保护机制，正是我们熟悉的 **`Redo Log`**。

当你执行一个更新，这个更新被写入 `Change Buffer` 时，**“将这个更新指令写入 Change Buffer”这个动作本身**，也会作为一个“重做日志条目”被记录到 `Redo Log` 中。

这样，如果机器在 `Change Buffer` 的内容还没来得及 `merge` 到磁盘数据页时就掉电了，数据库在重启恢复时会经历以下过程：
1.  `InnoDB` 会检查 `Redo Log`。
2.  它会发现一条日志写着：“嘿，我之前把一个‘要在 Page 2 插入一行’的指令放进了 `Change Buffer`”。
3.  于是，`InnoDB` 会根据这条 `Redo Log`，**重新把这个指令恢复到 `Change Buffer` 中**。

这样，数据就不会丢失了。`Change Buffer` 的内容被 `Redo Log` 忠实地保护着，保证了即使发生崩溃，这个优化机制本身也不会导致数据不一致或丢失。