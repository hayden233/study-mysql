我们来深入剖析一个在SQL开发中无处不在的操作：`ORDER BY`。

当查询结果需要排序时，MySQL 是如何在内部工作的？这背后其实有几种不同的算法，理解它们，可以帮助我们写出性能更好的排序查询。

-----

### 1\. `Using filesort`：当排序无法避免时

我们从一个常见的查询开始：

```sql
select city,name,age from t where city='杭州' order by name limit 1000;
```

假设我们在 `city` 字段上有一个索引。

这个查询的执行过程是：

1.  MySQL 使用 `city` 索引，快速找到所有 `city='杭州'` 的记录。
2.  但是，这些找到的记录是按主键 `id` 排序的，并非我们需要的 `name` 排序。
3.  因此，MySQL 必须在拿到所有满足条件的行之后，进行一次额外的排序操作。

在 `EXPLAIN` 的结果中，`Extra` 字段会显示 **`Using filesort`**。

**注意**：`filesort` 是一个容易让人误解的名字。它并不一定意味着使用了“磁盘文件”进行排序。它只是一个标志，表示 MySQL 需要一个明确的、独立的排序步骤。这个排序可能完全在内存中完成，也可能在内存不足时借助磁盘。

MySQL 会为每个需要排序的线程分配一块内存，称为 **`sort_buffer`**。接下来，我们看看 MySQL 在这个 `sort_buffer` 中排序的两种主要策略。

-----

### 2\. 排序策略一：全字段排序

这是 MySQL 优先选择的策略。

  * **工作流程**：

    1.  从 `city` 索引找到所有满足 `city='杭州'` 的主键 `id`。
    2.  根据每个 `id` **回表**，获取查询所需的所有字段（`city`, `name`, `age`）。
    3.  将这三个字段的完整内容，全部放入 `sort_buffer`。
    4.  当所有满足条件的行都放入 `sort_buffer` 后，在 `sort_buffer` 中按照 `name` 字段进行快速排序。
    5.  如果 `sort_buffer` 内存不够，就需要将数据分块，在磁盘上创建临时文件，对每个文件块进行排序，最后再将所有有序的文件块合并（归并排序）。
    6.  返回排序后的前1000行。

  * **优缺点**：

      * **优点**：排序完成后，结果集里包含了所有需要的字段，可以直接返回，无需再次访问数据表。
      * **缺点**：如果查询的字段很多、很大，`sort_buffer` 能容纳的行数就会很少，这会大大增加使用磁盘临时文件的概率，导致性能急剧下降。

### 3\. 排序策略二：rowid 排序

当 MySQL 判断待排序的单行数据太大（由 `max_length_for_sort_data` 参数控制）时，它会切换到一种更节省内存的策略。

  * **工作流程**：

    1.  从 `city` 索引找到所有满足 `city='杭州'` 的主键 `id`。
    2.  根据每个 `id` 回表，但这次**只获取排序需要的字段（`name`）和主键（`id`）**。
    3.  将这对 `(name, id)` 放入 `sort_buffer`。
    4.  当所有满足条件的 `(name, id)` 对都放入 `sort_buffer` 后，在其中进行排序。
    5.  排序完成后，取出前1000个 `(name, id)` 对。
    6.  拿着这1000个 `id`，**再次回到主键索引中去查询** 完整的 `city`, `name`, `age` 字段。
    7.  返回最终结果。

  * **优缺点**：

      * **优点**：因为 `sort_buffer` 中存放的数据量大大减少，排序过程更不容易使用磁盘，内存排序效率更高。
      * **缺点**：排序完成后，需要进行一次额外的**回表**操作，这增加了随机 I/O。

**MySQL 的设计思想**：如果内存足够，就尽量使用“全字段排序”，多用内存，少访问磁盘。只有在排序数据可能非常大的情况下，才会选择“rowid排序”，用一次额外的回表开销，来换取排序阶段更高的效率。

-----

### 4\. 终极优化：利用索引，避免排序

最高效的排序，就是**不排序**。我们可以通过创建合适的索引，使得从索引中取出的数据，天然就是有序的。

#### 优化方案一：创建联合索引

```sql
alter table t add index city_name(city, name);
```

这个索引的B+树结构，是先按 `city` 排序，在 `city` 相同的情况下，再按 `name` 排序。
当执行 `where city='杭州' order by name` 时：

1.  MySQL 通过 `(city, name)` 索引，直接定位到第一个 `city='杭州'` 的记录。
2.  从该位置开始，**顺序地向后扫描**索引。因为索引结构保证了，只要 `city` 还是 `杭州`，后续记录的 `name` 字段就一定是**天然有序**的。
3.  每扫描一条，就回表获取 `age` 字段，直到取满1000条。

在这个流程中，完全没有了 `sort_buffer` 的参与，也**没有了 `Using filesort`**，效率大幅提升。

#### 优化方案二：创建覆盖索引

这是最优方案。我们可以更进一步，创建一个包含所有查询字段的联合索引。

```sql
alter table t add index city_name_age(city, name, age);
```

当执行 `select city, name, age from t where city='杭州' order by name ...` 时：

1.  MySQL 同样通过这个索引定位到起点。
2.  顺序向后扫描，数据天然按 `name` 有序。
3.  最关键的是，这个查询需要的所有字段（`city`, `name`, `age`）**已经全部包含在索引中了**。
4.  因此，MySQL 无需回表，可以直接从索引中读取数据并返回。

此时，`EXPLAIN` 结果中不仅没有了 `Using filesort`，还会出现 **`Using index`**，表示使用了覆盖索引，这是性能最好的状态。

-----

### 结尾问题解析

> 假设有 `(city, name)` 联合索引，执行 `select * from t where city in ('杭州', '苏州') order by name limit 100;` 会有排序过程吗？如何实现一个在数据库端不需要排序的方案？分页怎么办？

**1. 会有排序过程吗？**
**答：会。** `EXPLAIN` 会显示 `Using filesort`。

**原因**：
`city in (...)` 对于优化器来说，是范围查询。它会使用 `(city, name)` 索引，但其工作方式是：

1.  先找出所有 `city='杭州'` 的记录，这部分记录内部按 `name` 有序。
2.  再找出所有 `city='苏州'` 的记录，这部分记录内部也按 `name` 有序。
3.  但是，MySQL 无法保证“杭州”的所有记录和“苏州”的所有记录合在一起后，整体仍然是按 `name` 有序的。比如，杭州最后一个人的名字是“王五”，苏州第一个人的名字是“李四”。
    因此，MySQL 必须将两个城市的结果集合并后，再进行一次全局的 `filesort`。

**2. 如何在数据库端不排序？**
**答：** 将一个复杂的查询，拆分成多个简单的、能利用索引有序性的查询，然后在\*\*应用层（代码中）\*\*进行合并。

```java
// 伪代码
// 1. 分别查询两个城市，并利用索引排序
List<User> hangzhouUsers = query("select name, age from t where city = '杭州' order by name limit 100");
List<User> suzhouUsers = query("select name, age from t where city = '苏州' order by name limit 100");

// 2. 在应用内存中进行归并排序
List<User> finalResult = mergeSort(hangzhouUsers, suzhouUsers);

// 3. 取出最终的前100条
return finalResult.subList(0, 100);
```

这个方案，把排序的压力从数据库转移到了应用服务器。对于取TOP N的场景是有效的。

**3. 分页怎么办（`limit 10000,100`）？**
**答：** 上述“应用层归并”的方案在分页（尤其是深度分页）时，会变得非常低效。因为要拿到全局的第10001条记录，你可能需要从杭州取出10100条，从苏州也取出10100条，然后在内存中合并后，再跳过10000条取100条，这非常浪费资源。

对于这种 `in` 条件下的深度分页排序，通常没有完美的、既不伤数据库也不伤应用的“银弹”。常见的处理方式有：

  * **方案一（接受数据库排序）**：这是最直接的。优化 `sort_buffer_size` 等参数，让数据库来硬抗 `filesort`。对于大多数中小型数据量的场景，这可能是最简单、成本最低的方案。
  * **方案二（业务妥协）**：和产品经理沟通，看是否能去掉这种跨城市的全局排序分页需求，或者将其改为“先选城市，再在城市内部分页排序”。
  * **方案三（复杂实现）**：如果必须实现，可以考虑更复杂的方案，比如将数据同步到 Elasticsearch 等专门的搜索系统，由它来处理这类复杂的排序和分页查询。